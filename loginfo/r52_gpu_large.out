[Epoch 0 Batch 4/117] loss=3.6893, lr=0.0000050, acc=0.125
[Epoch 0 Batch 8/117] loss=3.6554, lr=0.0000050, acc=0.133
[Epoch 0 Batch 12/117] loss=3.6284, lr=0.0000050, acc=0.174
[Epoch 0 Batch 16/117] loss=3.4070, lr=0.0000050, acc=0.248
[Epoch 0 Batch 20/117] loss=3.4997, lr=0.0000050, acc=0.292
[Epoch 0 Batch 24/117] loss=3.0500, lr=0.0000050, acc=0.356
[Epoch 0 Batch 28/117] loss=3.1561, lr=0.0000050, acc=0.378
[Epoch 0 Batch 32/117] loss=3.3327, lr=0.0000050, acc=0.377
[Epoch 0 Batch 36/117] loss=2.8156, lr=0.0000050, acc=0.403
[Epoch 0 Batch 40/117] loss=2.8454, lr=0.0000050, acc=0.418
[Epoch 0 Batch 44/117] loss=3.0006, lr=0.0000050, acc=0.417
[Epoch 0 Batch 48/117] loss=2.4957, lr=0.0000050, acc=0.435
[Epoch 0 Batch 52/117] loss=2.1872, lr=0.0000050, acc=0.455
[Epoch 0 Batch 56/117] loss=2.2285, lr=0.0000050, acc=0.467
[Epoch 0 Batch 60/117] loss=1.9703, lr=0.0000050, acc=0.483
[Epoch 0 Batch 64/117] loss=2.6576, lr=0.0000050, acc=0.480
[Epoch 0 Batch 68/117] loss=2.1038, lr=0.0000050, acc=0.488
[Epoch 0 Batch 72/117] loss=2.1603, lr=0.0000050, acc=0.494
[Epoch 0 Batch 76/117] loss=1.5770, lr=0.0000050, acc=0.510
[Epoch 0 Batch 80/117] loss=1.8015, lr=0.0000050, acc=0.519
[Epoch 0 Batch 84/117] loss=1.9330, lr=0.0000050, acc=0.525
[Epoch 0 Batch 88/117] loss=1.4154, lr=0.0000050, acc=0.536
[Epoch 0 Batch 92/117] loss=2.7729, lr=0.0000050, acc=0.531
[Epoch 0 Batch 96/117] loss=1.6945, lr=0.0000050, acc=0.532
[Epoch 0 Batch 100/117] loss=1.7151, lr=0.0000050, acc=0.534
[Epoch 0 Batch 104/117] loss=2.1099, lr=0.0000050, acc=0.534
[Epoch 0 Batch 108/117] loss=1.2976, lr=0.0000050, acc=0.540
[Epoch 0 Batch 112/117] loss=1.1379, lr=0.0000050, acc=0.549
[Epoch 0 Batch 116/117] loss=1.4982, lr=0.0000050, acc=0.553
[Epoch 1 Batch 4/117] loss=1.9732, lr=0.0000050, acc=0.537
[Epoch 1 Batch 8/117] loss=1.9635, lr=0.0000050, acc=0.542
[Epoch 1 Batch 12/117] loss=1.1180, lr=0.0000050, acc=0.596
[Epoch 1 Batch 16/117] loss=1.9105, lr=0.0000050, acc=0.596
[Epoch 1 Batch 20/117] loss=1.3275, lr=0.0000050, acc=0.622
[Epoch 1 Batch 24/117] loss=1.6023, lr=0.0000050, acc=0.620
[Epoch 1 Batch 28/117] loss=1.4066, lr=0.0000050, acc=0.632
[Epoch 1 Batch 32/117] loss=1.4036, lr=0.0000050, acc=0.637
[Epoch 1 Batch 36/117] loss=1.8698, lr=0.0000050, acc=0.629
[Epoch 1 Batch 40/117] loss=1.2632, lr=0.0000050, acc=0.640
[Epoch 1 Batch 44/117] loss=1.0716, lr=0.0000050, acc=0.655
[Epoch 1 Batch 48/117] loss=1.1805, lr=0.0000050, acc=0.662
[Epoch 1 Batch 52/117] loss=0.8186, lr=0.0000050, acc=0.675
[Epoch 1 Batch 56/117] loss=1.4885, lr=0.0000050, acc=0.673
[Epoch 1 Batch 60/117] loss=1.6296, lr=0.0000050, acc=0.667
[Epoch 1 Batch 64/117] loss=0.9391, lr=0.0000050, acc=0.676
[Epoch 1 Batch 68/117] loss=0.8508, lr=0.0000050, acc=0.684
[Epoch 1 Batch 72/117] loss=1.9163, lr=0.0000050, acc=0.676
[Epoch 1 Batch 76/117] loss=1.4775, lr=0.0000050, acc=0.675
[Epoch 1 Batch 80/117] loss=1.1726, lr=0.0000050, acc=0.679
[Epoch 1 Batch 84/117] loss=1.0623, lr=0.0000050, acc=0.684
[Epoch 1 Batch 88/117] loss=1.0206, lr=0.0000050, acc=0.687
[Epoch 1 Batch 92/117] loss=1.4055, lr=0.0000050, acc=0.686
[Epoch 1 Batch 96/117] loss=1.4855, lr=0.0000050, acc=0.686
[Epoch 1 Batch 100/117] loss=1.1190, lr=0.0000050, acc=0.691
[Epoch 1 Batch 104/117] loss=1.3213, lr=0.0000050, acc=0.692
[Epoch 1 Batch 108/117] loss=1.4708, lr=0.0000050, acc=0.690
[Epoch 1 Batch 112/117] loss=1.6025, lr=0.0000050, acc=0.689
[Epoch 1 Batch 116/117] loss=1.3840, lr=0.0000050, acc=0.689
[Epoch 2 Batch 4/117] loss=1.2133, lr=0.0000050, acc=0.719
[Epoch 2 Batch 8/117] loss=0.5427, lr=0.0000050, acc=0.789
[Epoch 2 Batch 12/117] loss=1.5868, lr=0.0000050, acc=0.729
[Epoch 2 Batch 16/117] loss=1.1215, lr=0.0000050, acc=0.746
[Epoch 2 Batch 20/117] loss=0.6856, lr=0.0000050, acc=0.778
[Epoch 2 Batch 24/117] loss=1.5189, lr=0.0000050, acc=0.762
[Epoch 2 Batch 28/117] loss=0.8948, lr=0.0000050, acc=0.770
[Epoch 2 Batch 32/117] loss=1.0907, lr=0.0000050, acc=0.775
[Epoch 2 Batch 36/117] loss=1.0100, lr=0.0000050, acc=0.779
[Epoch 2 Batch 40/117] loss=0.9502, lr=0.0000050, acc=0.780
[Epoch 2 Batch 44/117] loss=1.4422, lr=0.0000050, acc=0.767
[Epoch 2 Batch 48/117] loss=1.6379, lr=0.0000050, acc=0.757
[Epoch 2 Batch 52/117] loss=0.5455, lr=0.0000050, acc=0.767
[Epoch 2 Batch 56/117] loss=1.1517, lr=0.0000050, acc=0.763
[Epoch 2 Batch 60/117] loss=1.3160, lr=0.0000050, acc=0.758
[Epoch 2 Batch 64/117] loss=0.5916, lr=0.0000050, acc=0.766
[Epoch 2 Batch 68/117] loss=0.7843, lr=0.0000050, acc=0.767
[Epoch 2 Batch 72/117] loss=0.9940, lr=0.0000050, acc=0.767
[Epoch 2 Batch 76/117] loss=1.1644, lr=0.0000050, acc=0.764
[Epoch 2 Batch 80/117] loss=1.1143, lr=0.0000050, acc=0.763
[Epoch 2 Batch 84/117] loss=0.5050, lr=0.0000050, acc=0.770
[Epoch 2 Batch 88/117] loss=1.2372, lr=0.0000050, acc=0.768
[Epoch 2 Batch 92/117] loss=1.0092, lr=0.0000050, acc=0.765
[Epoch 2 Batch 96/117] loss=0.5674, lr=0.0000050, acc=0.771
[Epoch 2 Batch 100/117] loss=1.6082, lr=0.0000050, acc=0.767
[Epoch 2 Batch 104/117] loss=0.9878, lr=0.0000050, acc=0.767
[Epoch 2 Batch 108/117] loss=0.5974, lr=0.0000050, acc=0.771
[Epoch 2 Batch 112/117] loss=1.2132, lr=0.0000050, acc=0.771
[Epoch 2 Batch 116/117] loss=1.5528, lr=0.0000050, acc=0.767
[Epoch 3 Batch 4/117] loss=1.0283, lr=0.0000050, acc=0.766
[Epoch 3 Batch 8/117] loss=0.5635, lr=0.0000050, acc=0.824
[Epoch 3 Batch 12/117] loss=0.9266, lr=0.0000050, acc=0.820
[Epoch 3 Batch 16/117] loss=0.4216, lr=0.0000050, acc=0.837
[Epoch 3 Batch 20/117] loss=1.0552, lr=0.0000050, acc=0.831
[Epoch 3 Batch 24/117] loss=0.7416, lr=0.0000050, acc=0.836
[Epoch 3 Batch 28/117] loss=1.1375, lr=0.0000050, acc=0.824
[Epoch 3 Batch 32/117] loss=0.6875, lr=0.0000050, acc=0.831
[Epoch 3 Batch 36/117] loss=0.8547, lr=0.0000050, acc=0.838
[Epoch 3 Batch 40/117] loss=1.0640, lr=0.0000050, acc=0.830
[Epoch 3 Batch 44/117] loss=0.5479, lr=0.0000050, acc=0.833
[Epoch 3 Batch 48/117] loss=0.6402, lr=0.0000050, acc=0.837
[Epoch 3 Batch 52/117] loss=1.1587, lr=0.0000050, acc=0.827
[Epoch 3 Batch 56/117] loss=0.7403, lr=0.0000050, acc=0.830
[Epoch 3 Batch 60/117] loss=0.5591, lr=0.0000050, acc=0.832
[Epoch 3 Batch 64/117] loss=0.7802, lr=0.0000050, acc=0.832
[Epoch 3 Batch 68/117] loss=0.7640, lr=0.0000050, acc=0.830
[Epoch 3 Batch 72/117] loss=0.8545, lr=0.0000050, acc=0.827
[Epoch 3 Batch 76/117] loss=0.7102, lr=0.0000050, acc=0.830
[Epoch 3 Batch 80/117] loss=0.7018, lr=0.0000050, acc=0.830
[Epoch 3 Batch 84/117] loss=1.1292, lr=0.0000050, acc=0.828
[Epoch 3 Batch 88/117] loss=1.1531, lr=0.0000050, acc=0.824
[Epoch 3 Batch 92/117] loss=0.7757, lr=0.0000050, acc=0.825
[Epoch 3 Batch 96/117] loss=0.7649, lr=0.0000050, acc=0.824
[Epoch 3 Batch 100/117] loss=0.6810, lr=0.0000050, acc=0.827
[Epoch 3 Batch 104/117] loss=0.9123, lr=0.0000050, acc=0.826
[Epoch 3 Batch 108/117] loss=0.7323, lr=0.0000050, acc=0.827
[Epoch 3 Batch 112/117] loss=0.7653, lr=0.0000050, acc=0.826
[Epoch 3 Batch 116/117] loss=1.2592, lr=0.0000050, acc=0.823
Saving model at  ./model_bert_r52_large
load symbol file directly as SymbolBlock for model deployment.
[Batch 4/53], acc = 0.827
[Batch 8/53], acc = 0.830
[Batch 12/53], acc = 0.830
[Batch 16/53], acc = 0.833
[Batch 20/53], acc = 0.835
[Batch 24/53], acc = 0.836
[Batch 28/53], acc = 0.837
[Batch 32/53], acc = 0.841
[Batch 36/53], acc = 0.844
[Batch 40/53], acc = 0.845
[Batch 44/53], acc = 0.845
[Batch 48/53], acc = 0.844
[Batch 52/53], acc = 0.846
EvalMetric: {'accuracy': 0.8469626168224299}
Time cost = 24.12 s, throughput = 35.16 samples/s
